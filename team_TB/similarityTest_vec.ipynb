{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omayya/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-03 20:56:14.171665: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-03 20:56:14.171812: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (omayya-vm): /proc/driver/nvidia/version does not exist\n",
      "/home/omayya/.local/lib/python3.10/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'fr_core_news_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from processingQst import *\n",
    "from similarityFcts import *\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./input/csv/dev.csv\",delimiter=\";\")\n",
    "\n",
    "Qst = df[\"question\"]\n",
    "id  = df[\"id\"]\n",
    "nbrRepAll = df[\"nbr_correct_answers\"]\n",
    "RepListIndxAll = df[\"correct_answers\"]\n",
    "nbrRep = 5\n",
    "print(len(Qst))\n",
    "data_list = []\n",
    "RepListIndx = 'abcde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusMS = openJson(\"output/corpusMS.json\")\n",
    "corpusMrk = openJson(\"output/corpusMerck.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepDBV2(keywordsQ,nwQstp,corpusMS,corpusMrk):\n",
    "    keywordsR_MS = [item['keywords'] for item in corpusMS]\n",
    "    keywordsR_Mrk = [item['keywords'] for item in corpusMrk]\n",
    "\n",
    "    str_keywordsQ = \" \".join(keywordsQ)\n",
    "    str_keywordsR_MS = [\" \".join(lst) for lst in keywordsR_MS]\n",
    "    str_keywordsR_Mrk = [\" \".join(lst) for lst in keywordsR_Mrk]\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    X_Mrk = vectorizer.fit_transform([str_keywordsQ] + str_keywordsR_Mrk)\n",
    "    v1_Mrk = X_Mrk[0]\n",
    "    v2_Mrk = X_Mrk[1:]\n",
    "    similarity_Mrk = cosine_similarity(v1_Mrk, v2_Mrk)[0]\n",
    "    indx_Mrk = np.argmax(similarity_Mrk)\n",
    "    print(indx_Mrk)\n",
    "    _, rate_Mrk = ComMembList(keywordsQ, keywordsR_Mrk[indx_Mrk-1], tol=90)\n",
    "\n",
    "    print(rate_Mrk)\n",
    "\n",
    "    # print(f\"La liste la plus similaire est la liste {indx_Mrk} : {keywordsR_Mrk[indx_Mrk-1]}\")\n",
    "    \n",
    "    X_MS = vectorizer.fit_transform([str_keywordsQ] + str_keywordsR_MS)\n",
    "    v1_MS = X_MS[0]\n",
    "    v2_MS = X_MS[1:]\n",
    "    similarity_MS = cosine_similarity(v1_MS, v2_MS)[0]\n",
    "    indx_MS = np.argmax(similarity_MS)\n",
    "    print(indx_MS)\n",
    "\n",
    "    _, rate_MS = ComMembList(keywordsQ, keywordsR_Mrk[indx_MS-1], tol=90)\n",
    "\n",
    "    print(rate_MS)\n",
    "\n",
    "    # print(f\"La liste la plus similaire est la liste {indx_MS} : {keywordsR_MS[indx_MS-1]}\")\n",
    "\n",
    "    return indx_Mrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adrénaline', 'stimule', 'processus', 'métabolique', 'glycolyse']\n",
      "15285\n",
      "0\n",
      "50\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for cpt in range(len(Qst)):\n",
    "# for cpt in tqdm(range(len(Qst))):\n",
    "    if (cpt > 0):\n",
    "        break\n",
    "    elif (cpt>=0): \n",
    "        qst = Qst[cpt]\n",
    "        nwQst = ''\n",
    "        listMed = []\n",
    "        listMedR = []\n",
    "        keywordsQ = []\n",
    "        listMedQst = []\n",
    "        ListMedAns = ''\n",
    "        Spword = False\n",
    "        data_dict = {}\n",
    "\n",
    "        # Détécter la négation \n",
    "        if(isRequestWrongAns(qst)):\n",
    "            WrongQst = True \n",
    "            # print(WrongQst)\n",
    "        else: \n",
    "            WrongQst = False \n",
    "            # print(WrongQst)\n",
    "        \n",
    "        # supprimer les parenthèses \n",
    "        qst = del_betParenthese(qst)\n",
    "\n",
    "        # fragementation des questions selon les \",\"\n",
    "        fragQst = splitQst(qst)\n",
    "\n",
    "        for icpt in range(len(fragQst)):\n",
    "            if not (fragQst[icpt]==''):\n",
    "                nwQst,Spword,listMed = recoverMedFrag(fragQst,icpt,nwQst,Spword)\n",
    "                listMedQst.extend(listMed)\n",
    "        nwQst = nwQst.lstrip()\n",
    "        nwQstp = ''\n",
    "        for j in range(1): # 5 réponses \n",
    "            Ans = df[f\"answers.{RepListIndx[j]}\"][cpt] \n",
    "            Ans = Ans.lstrip()\n",
    "            listMedR = RecoverListMed(Ans)\n",
    "            keywordsQ.extend(listMedQst)\n",
    "            keywordsQ.extend(listMedR)\n",
    "            if Spword:\n",
    "                nwQstp = replaceAtFront(Ans) + nwQst + '.'\n",
    "            else:\n",
    "                nwQstp = nwQst + ' '+ Ans.lower() + '.' \n",
    "            # Appliquer la négation \n",
    "            if WrongQst == True:\n",
    "                nwQstp = appliquer_negation(nwQstp.lower())\n",
    "            \n",
    "            print(keywordsQ)\n",
    "            # test de similarité \n",
    "            indx = getRepDBV2(keywordsQ,nwQstp,corpusMS,corpusMrk)\n",
    "            # taux_sim = getRepDB(keywordsQ,nwQstp)\n",
    "            # print(taux_sim)\n",
    "            # print(indx)\n",
    "            # créer un dataframe pour les données actuelles\n",
    "#             data_dict = {'id' : id[cpt], 'ListMed': keywordsQ, 'qst': nwQstp}\n",
    "#             data_list.append(data_dict)\n",
    "#             nwQstp = ''\n",
    "#             keywordsQ = []\n",
    "\n",
    "# writeJson(\"output/Qst_dev.json\",data_list)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
