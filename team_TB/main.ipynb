{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:40:15.827774: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 14:40:16.220753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-06 14:40:17.258571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-06 14:40:17.275534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-06 14:40:17.275880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "/home/amani/.local/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from processingQst import *\n",
    "from similarityFcts import *\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2171\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./input/csv/train.csv\",delimiter=\";\")\n",
    "\n",
    "Qst = df[\"question\"]\n",
    "id  = df[\"id\"]\n",
    "nbrRepAll = df[\"nbr_correct_answers\"]\n",
    "RepListIndxAll = df[\"correct_answers\"]\n",
    "nbrRep = 5\n",
    "print(len(Qst))\n",
    "data_list = []\n",
    "RepListIndx = 'abcde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJson(path,data):\n",
    "    with open(path,\"w\",encoding='utf-8') as f:\n",
    "        json.dump(data,f,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = ['bactérie','méningite']\n",
    "with open('output/corpusMS.json', 'r') as f:\n",
    "    corpusA = json.load(f)\n",
    "with open('output/corpusMerck.json', 'r') as fs:\n",
    "    corpusB = json.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cpt in range(len(Qst)):\n",
    "# for cpt in tqdm(range(len(Qst))):\n",
    "    if (cpt > 0):\n",
    "        break\n",
    "    elif (cpt>=0): \n",
    "        qst = Qst[cpt]\n",
    "        # print(qst)\n",
    "        nwQst = ''\n",
    "        listMed = []\n",
    "        keywordQ = []\n",
    "        keywordQP = []\n",
    "        ListMedAns = ''\n",
    "        Spword = False\n",
    "        data_dict = {}\n",
    "\n",
    "        # Détécter la négation \n",
    "        if(isRequestWrongAns(qst)):\n",
    "            WrongQst = True \n",
    "            # print(WrongQst)\n",
    "        else: \n",
    "            WrongQst = False \n",
    "            # print(WrongQst)\n",
    "        \n",
    "        # supprimer les parenthèses \n",
    "        qst = del_betParenthese(qst)\n",
    "\n",
    "        # fragementation des questions selon les \",\"\n",
    "        fragQst = splitQst(qst)\n",
    "\n",
    "        for icpt in range(len(fragQst)):\n",
    "            if not (fragQst[icpt]==''):\n",
    "                nwQst,Spword,listMed = recoverMedFrag(fragQst,icpt,nwQst,Spword)\n",
    "                keywordQ.extend(listMed)\n",
    "        nwQst = nwQst.lstrip()\n",
    "        nwQstp = ''\n",
    "        var = ''\n",
    "        for j in range(5):\n",
    "            keywordQP = []\n",
    "            Ans = df[f\"answers.{RepListIndx[j]}\"][cpt] \n",
    "            Ans = Ans.lstrip()\n",
    "            keywordQP.extend(RecoverListMed(Ans))\n",
    "            if Spword:\n",
    "                nwQstp = replaceAtFront(Ans) + nwQst + '.'\n",
    "            else:\n",
    "                nwQstp = nwQst + ' '+ Ans.lower() + '.' \n",
    "            # Appliquer la négation \n",
    "            if WrongQst == True:\n",
    "                nwQstp = appliquer_negation(nwQstp.lower())\n",
    "            \n",
    "            # # test de similarité \n",
    "            # print(\"----\")\n",
    "            print(nwQstp)\n",
    "            # print(keywordQ)\n",
    "            # print(keywordQP)\n",
    "            taux_sim = getRepDB(keywordQ,keywordQP,corpusA,nwQstp)\n",
    "            taux_simB = 0# getRepDB(keywordQ,keywordQP,corpusB,nwQstp)\n",
    "            if taux_sim>0.90 or taux_simB>0.90:\n",
    "                if var !=\"\":\n",
    "                    var = var + '|'\n",
    "                var = var + RepListIndx[j]\n",
    "            \n",
    "        # créer un dataframe pour les données actuelles\n",
    "        data_dict = {'id': id[cpt], 'correction': var}\n",
    "        data_list.append(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeJson(\"output/Qst_dev.json\",data_list)\n",
    "df = pd.DataFrame(data_list)\n",
    "df.to_csv('./output/tachePrincipale.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
