{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed4f495",
   "metadata": {},
   "source": [
    "# Tâche réalisée\n",
    "\n",
    "Ici, la tâche réalisée est la création d'un jeu de données complémentaire afin de détecter des technolectes médicaux liés.\n",
    "\n",
    "Nous avons prit l'ensemble du corpus Mesh FR et nous avons réalisé les étapes suivantes :\n",
    "- **Ouverture des colonnes jugées intéressantes du corpus** : ces colonnes contiennent une nombre important de termes médicaux, mais également des termes courants pouvant être utilisé dans le champs lexical de la médecine, et qui jusqu'alors étaient supprimés.\n",
    "- **Nettoyage des colonnes ouvertes** : on en retire la ponctuation et les mots vides afin de ne garder que les termes prévalents.\n",
    "- **Sauvegarde dans un fichier** : on conserve précieusement ce vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc07a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string as strii\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "sp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def openJson(path):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data     \n",
    "\n",
    "def writeJson(path,data):\n",
    "    with open(path,\"w\",encoding='utf-8') as f:\n",
    "        json.dump(data,f,indent=4,ensure_ascii=False)\n",
    "\n",
    "def removePunct(string):\n",
    "    return string.translate(str.maketrans(strii.punctuation, ' '*len(strii.punctuation))) #map punctuation to space\n",
    "\n",
    "def tokenizer(string):\n",
    "    sp.max_length = 10500000\n",
    "    spacy_object = sp(string, disable = ['ner', 'parser'])\n",
    "    return [word.text for word in spacy_object if word.is_stop == False] #and word.pos_ != \"PUNCT\" and word.pos_ != \"NUM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b406f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture du fichier\n",
    "\n",
    "df = pd.read_csv(\"input/MESHFRENSH.csv\",delimiter=\",\")\n",
    "\n",
    "labels = [str(l).lower() for l in df[\"Label\"]]\n",
    "synonyms = [str(s).lower() for s in df[\"Synonyms\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f543c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une liste de mots clefs médicaux à partir de Mesh\n",
    "\n",
    "labels = tokenizer(removePunct(\" \".join(labels)))\n",
    "synonyms = tokenizer(removePunct(\" \".join(synonyms)))\n",
    "\n",
    "keywords = list(set(labels+synonyms))\n",
    "writeJson(\"output/corpusRef/keywordsMesh.json\",keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866afbe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "writeJson() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m liste_keywords:\n\u001b[1;32m     11\u001b[0m         liste_mots_without_mesh_mots\u001b[38;5;241m.\u001b[39mappend(word)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mwriteJson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/corpusRef/mots_fr_without_mesh_words.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: writeJson() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "#Création d'une liste en épargant les termes présents dans Mesh\n",
    "\n",
    "liste = \"input/liste.de.mots.francais.frgut.txt\"\n",
    "with open(liste,'r',encoding='utf-8') as f:\n",
    "     liste_mots = [line.rstrip('\\n').lower() for line in f]\n",
    "liste_keywords = openJson(\"output/corpusRef/keywordsMesh.json\")\n",
    "\n",
    "liste_mots_without_mesh_mots = []\n",
    "for word in liste_mots:\n",
    "    if word not in liste_keywords:\n",
    "        liste_mots_without_mesh_mots.append(word)\n",
    "writeJson(\"output/corpusRef/mots_fr_without_mesh_words.json\",liste_mots_without_mesh_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d3faaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)        \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m liste_mots_without_mesh_mots:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mwriteOutputFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mliste_mots_without_mesh_mots\u001b[49m\u001b[43m,\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m      \n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mwriteOutputFile\u001b[0;34m(path, string)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriteOutputFile\u001b[39m(path,string):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:275\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(io_open)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_modified_open\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "def writeOutputFile(path,string):\n",
    "    with open(path, 'a',encoding='utf-8') as f:\n",
    "        f.write(f\"{string}\\n\")        \n",
    "\n",
    "for word in liste_mots_without_mesh_mots:\n",
    "    writeOutputFile(\"output/corpusRef/mots_fr_without_mesh_words.txt\",word)      \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEFT2023",
   "language": "python",
   "name": "deft2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
