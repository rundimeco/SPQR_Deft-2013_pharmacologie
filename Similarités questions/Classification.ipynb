{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc83f71",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- effectuer les similarités entre technolectes de questions en questions et de réponses en réponses.\n",
    "- faire de même entre une question et ses réponses ?\n",
    "\n",
    "\n",
    "### Ce qui a été fait\n",
    "\n",
    "J'ai essayé de faire une première classification par règles. Pour chaque question, je crée des similarités cosinus au mot entre cette question et les autres questions et entre sa réponse et les autres réponses. Toujours pour chaque question, je ne garde que les résultats supérieurs à 0.8 (valeur à modifier par la suite ?). \n",
    "\n",
    "Suite à cela, j'ai favorisé une approche plus normée. Les questions sont \"bruitées\" quand on parle de similarité : beaucoup de termes en commun ne donnant aucun indice sur la réponse à trouver. De plus, une similarité au mot semble peu utile. Il faudrait conserver **exclusivement les technolectes appartenant au champs lexical de la médecine aussi bien dans les questions que dans les réponses**. Avec ces technolectes, on peut ensuite faire de similarités au caractère, plus pertinentes selon moi dans ce contexte.\n",
    "\n",
    "Les règles de nettoyage sont les suivantes :\n",
    "\n",
    "- suppression des mots vides, de la ponctuation et des mots d'une longueur de 1. On ignore la case SANS LA SUPPRIMER pour autant.\n",
    "- on parcours une liste de mots du français (deux listes trouvées, une de 20 000 et plus occurrences, l'autre de 300 000 et plus occurrences) et pour chaque mot reconnu on l'exclu du vocabulaire des technolectes.\n",
    "- à la fin, on a une liste de mots qui ne sont pas retrouvés dans la liste de mots du français utilisée, la plupart étant des technolectes propres au champs lexical de la médecine.\n",
    "\n",
    "\n",
    "### Remarques personnelles sur la tâche\n",
    "\n",
    "Je distingue deux approches au problème :\n",
    "\n",
    "- une approche visant à savoir si le jeu de données peut se suffire afin d'obtenir de meilleurs résultats que ceux obtenus dans le papier \"source\" : X questions nous donnent Y indices sur un concept médical, donc on a des liens entre mots clefs au sein du corpus qu'on exploite par la suite.\n",
    "- une approche visant à créer ou exploiter une base de données médicale suffisement exhaustive afin de permettre une reconnaissance de termes clef entre eux : terme clef A de la question est plus souvent lié au terme B de la réponse X dans un contexte médical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40819032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports et fonctions\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import string as strii\n",
    "\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "sp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def removePunct(string):\n",
    "    return string.translate(str.maketrans(strii.punctuation, ' '*len(strii.punctuation))) #map punctuation to space\n",
    "\n",
    "def tokenizer(string):\n",
    "    spacy_object = sp(string)\n",
    "    return [word.text for word in spacy_object if word.is_stop == False] #and word.pos_ != \"PUNCT\" and word.pos_ != \"NUM\"\n",
    "\n",
    "def makeVoc(liste):\n",
    "    voc = []\n",
    "    for item in liste:\n",
    "        for word in tokenizer(removePunct(item)):\n",
    "            if word not in voc:\n",
    "                voc.append(word)\n",
    "    return [w for w in voc if len(w) > 1]\n",
    "\n",
    "def vectorizer(q,liste_q,ngram_range=(1,1),analyzer=\"word\"): #analyzer{‘word’, ‘char’, ‘char_wb’}\n",
    "    #vect = TfidfVectorizer()\n",
    "    vect = CountVectorizer(lowercase=True,ngram_range=ngram_range, analyzer=analyzer)\n",
    "    liste_q_vect = vect.fit_transform(liste_q) #vectoriser cet ensemble à part ? gain de temps\n",
    "    liste_q_term_matrix = liste_q_vect.toarray()\n",
    "    q_vect = vect.transform([q]).toarray()\n",
    "    return q_vect,liste_q_term_matrix\n",
    "    \n",
    "def cosinus(q_vect,liste_q_term_matrix):\n",
    "    return cosine_similarity(liste_q_term_matrix,q_vect)\n",
    "\n",
    "def writeJson(path,data):\n",
    "    with open(path,\"w\",encoding='utf-8') as f:\n",
    "        json.dump(data,f,indent=4,ensure_ascii=False)\n",
    "        \n",
    "def openJson(path):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8456032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du jeu de données et ajout d'une concaténation des réponses\n",
    "\n",
    "df = pd.read_csv(\"../data/csv/train.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829f8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du vocabulaire cible composé de technolectes\n",
    "\n",
    "liste = \"input/liste.de.mots.francais.frgut.txt\"\n",
    "with open(liste,'r',encoding='utf-8') as f:\n",
    "     liste_mots = [line.rstrip('\\n').lower() for line in f]\n",
    "liste_keywords = openJson(\"output/corpusRef/keywordsMesh.json\")\n",
    "\n",
    "voc_global = set(makeVoc(df[\"question\"]))\n",
    "\n",
    "voc_medical = []\n",
    "for word in voc_global:\n",
    "    if len(word) > 1:\n",
    "        if word.lower() not in liste_mots:\n",
    "            voc_medical.append(word)\n",
    "        elif word.lower() in liste_keywords:\n",
    "            voc_medical.append(word)\n",
    "\n",
    "writeJson('output/classification/vocabulaire médical.json',voc_medical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b50806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Première tâche de similarité : test en ngram char_wb\n",
    "\n",
    "voc_medical = openJson(\"output/classification/vocabulaire médical.json\")\n",
    "dic = {}\n",
    "\n",
    "ids = df[\"id\"]\n",
    "questions = df[\"question\"]\n",
    "\n",
    "ids_merged_q = []\n",
    "merged_q = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    voc_m_q = [w for w in removePunct(questions[i]).split() if w in voc_medical]\n",
    "    if len(voc_m_q) > 0:\n",
    "        merged_q.append(\" \".join(voc_m_q))\n",
    "        ids_merged_q.append(ids[i])\n",
    "\n",
    "for i,mq in enumerate(merged_q):\n",
    "    dic[ids_merged_q[i]] = {}\n",
    "    vect_mq,vect_merged_q = vectorizer(mq,merged_q,ngram_range=(1,3),analyzer=\"char_wb\")\n",
    "    cos = [list(s) for s in cosinus(vect_mq,vect_merged_q)]\n",
    "    for j,res in enumerate(cos):\n",
    "        dic[ids_merged_q[i]][ids_merged_q[j]] = cos[j][0]\n",
    "    \n",
    "writeJson(\"sims.json\",dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef718a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation des résultats : classification des paires q/r similaires selon un seuil\n",
    "\n",
    "data = openJson(\"sims.json\")\n",
    "similarities_classes = []\n",
    "\n",
    "for ib, subdic in data.items():\n",
    "    sim_classe = []\n",
    "    for k,v in subdic.items():\n",
    "        if v > 0.8:\n",
    "            sim_classe.append(k)\n",
    "    similarities_classes.append(sim_classe)\n",
    "    \n",
    "#similarities_classes_clean = []\n",
    "#for l in similarities_classes:\n",
    "#    if len(l) > 1:\n",
    "#        similarities_classes_clean.append(l)\n",
    "    \n",
    "#on sauvegarde les clusters en supprimant les classes identiques ET LES CLASSES D'UN ELEMENT\n",
    "writeJson(\"output/classification/id_classes.json\",[list(item) for item in set(tuple(row) for row in similarities_classes)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f1d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si on souhaite observer le rendu de la classification\n",
    "\n",
    "data = openJson(\"output/classification/id_classes.json\")\n",
    "\n",
    "questions_list = []\n",
    "for l in data:\n",
    "    new_l = []\n",
    "    for i in range(len(df)):\n",
    "        if df[\"id\"][i] in l:\n",
    "            new_l.append(df[\"question\"][i])\n",
    "    questions_list.append(new_l)\n",
    "    \n",
    "writeJson(\"output/classification/content_classes.json\",questions_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e44016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2171\n",
      "1796\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "id_classes = openJson(\"output/classification/id_classes.json\")\n",
    "df = pd.read_csv(\"../corpus_builder/new_csv.csv\",delimiter=\",\",index_col=0)\n",
    "\n",
    "related_lines = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    rl = []\n",
    "    for liste in id_classes:\n",
    "        if df[\"id\"][i] in liste:\n",
    "            rl = rl + liste\n",
    "    related_lines.append(list(set(rl)))\n",
    "    \n",
    "df[\"questions_related_to\"] = related_lines\n",
    "df.to_csv(\"../corpus_builder/new_csv.csv\",index=True)\n",
    "\"\"\"\n",
    "\n",
    "print(len(df))\n",
    "print(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEFT2023",
   "language": "python",
   "name": "deft2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
