{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed4f495",
   "metadata": {},
   "source": [
    "# Tâche réalisée\n",
    "\n",
    "Ici, la tâche réalisée est la création d'un jeu de données complémentaire afin de détecter des technolectes médicaux liés.\n",
    "\n",
    "Nous avons prit l'ensemble du corpus Mesh FR et nous avons réalisé les étapes suivantes :\n",
    "- **Ouverture des colonnes jugées intéressantes du corpus** : ces colonnes contiennent une nombre important de termes médicaux, mais également des termes courants pouvant être utilisé dans le champs lexical de la médecine, et qui jusqu'alors étaient supprimés.\n",
    "- **Nettoyage des colonnes ouvertes** : on en retire la ponctuation et les mots vides afin de ne garder que les termes prévalents.\n",
    "- **Sauvegarde dans un fichier** : on conserve précieusement ce vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc07a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string as strii\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "sp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def writeJson(path,data):\n",
    "    with open(path,\"w\",encoding='utf-8') as f:\n",
    "        json.dump(data,f,indent=4,ensure_ascii=False)\n",
    "\n",
    "def removePunct(string):\n",
    "    return string.translate(str.maketrans(strii.punctuation, ' '*len(strii.punctuation))) #map punctuation to space\n",
    "\n",
    "def tokenizer(string):\n",
    "    sp.max_length = 10500000\n",
    "    spacy_object = sp(string, disable = ['ner', 'parser'])\n",
    "    return [word.text for word in spacy_object if word.is_stop == False] #and word.pos_ != \"PUNCT\" and word.pos_ != \"NUM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b406f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture du fichier\n",
    "\n",
    "df = pd.read_csv(\"input/MESHFRENSH.csv\",delimiter=\",\")\n",
    "\n",
    "labels = [str(l).lower() for l in df[\"Label\"]]\n",
    "synonyms = [str(s).lower() for s in df[\"Synonyms\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f543c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une liste de mots clefs médicaux à partir de Mesh\n",
    "\n",
    "labels = tokenizer(removePunct(\" \".join(labels)))\n",
    "synonyms = tokenizer(removePunct(\" \".join(synonyms)))\n",
    "\n",
    "keywords = list(set(labels+synonyms))\n",
    "writeJson(\"output/corpusRef/keywordsMesh.json\",keywords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEFT2023",
   "language": "python",
   "name": "deft2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
