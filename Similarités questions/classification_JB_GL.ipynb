{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc83f71",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- voir si je peux utiliser la classification de Toufik afin de \"nettoyer\" les questions des structures récurrentes (voir classes Toufik). Une comparaison de similarité sur les termes médicaux seulement, où on unifie les termes médicaux de la question et de la réponse avant de faire des similarités par n-gram de caractères entre ces ensembles ?\n",
    "\n",
    "- même idée, mais avec les phrases formées par Corina\n",
    "\n",
    "\n",
    "### Ce qui a été fait\n",
    "\n",
    "J'ai essayé de faire une première classification par règles. Pour chaque question, je crée des similarités cosinus au mot entre cette question et les autres questions et entre sa réponse et les autres réponses. Toujours pour chaque question, je ne garde que les résultats supérieurs à 0.8 (valeur à modifier par la suite ?). \n",
    "\n",
    "### Résultat\n",
    "\n",
    "Comme on pouvait s'y attendre, on ne remarque pas grand chose. Les ensembles créés pour chaque question rassemblent souvent entre eux les questions avec des formes récurrentes (voir classes Toufik). Il faudrait pour chaque question indiquer à quelle classe elle appartient et, en fonction de la classe, extraire le segment contenant l'information médicale. \n",
    "\n",
    "Une fois que nous récupérons ce segment de la question, nous le plaçons dans une liste avec les réponses à la question, qui sont elles aussi des informations médicales. De là, on pourrait faire une similarité entre cet ensemble \\[segment question / réponse\\] et les autres ensembles \\[segment question / réponse\\].\n",
    "\n",
    "### Remarques personnelles sur la tâche\n",
    "\n",
    "Je distingue deux approches au problème :\n",
    "\n",
    "- une approche visant à savoir si le jeu de données peut se suffire afin d'obtenir de meilleurs résultats que ceux obtenus dans le papier \"source\" : X questions nous donnent Y indices sur un concept médical, donc on a des liens entre mots clefs au sein du corpus qu'on exploite par la suite.\n",
    "\n",
    "- une approche visant à créer ou exploiter une base de données médicale suffisement exhaustive afin de permettre une reconnaissance de termes clef entre eux : terme clef A de la question est plus souvent lié au terme B de la réponse X dans un contexte médical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40819032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports et fonctions\n",
    "\n",
    "import json\n",
    "\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosinus(q,liste_q):\n",
    "    #vect = TfidfVectorizer()\n",
    "    vect = CountVectorizer()\n",
    "    liste_q_vect = vect.fit_transform(liste_q)\n",
    "    doc_term_matrix = liste_q_vect.toarray()\n",
    "\n",
    "    tgt_transform = vect.transform([q]).toarray()\n",
    "    tgt_cosine = cosine_similarity(doc_term_matrix,tgt_transform)\n",
    "    return tgt_cosine\n",
    "\n",
    "def writeJson(path,data):\n",
    "    with open(path,\"w\",encoding='utf-8') as f:\n",
    "        json.dump(data,f,indent=4,ensure_ascii=False) #sans le ensure_ascii on a des erreurs d'encodage sur les accents / char speciaux / emojis sur Windows\n",
    "        \n",
    "def openJson(path):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5b0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'un corpus de similarités entre questions et entre réponses aux questions (bonnes réponses uniquement)\n",
    "\"\"\"\n",
    "Similarité : cosinus\n",
    "ce qui est comparé : une question avec toutes les autres questions du jeu de données\n",
    "                     les réponses à une question avec toutes les réponses aux autres questions\n",
    "ce qu'on obtient : un dictionnaire avec l'id d'une question Q1, le réponses à Q1, et \n",
    "un subdic avec l'id, les réponses et la similarité de chaque question par rapport à Q1\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dic = {}\n",
    "df = pd.read_csv(\"../data/csv/train.csv\",delimiter=\";\")\n",
    "\n",
    "ids = []\n",
    "questions = []\n",
    "reponses = []\n",
    "total_reponses = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ids.append(df[\"id\"][i])\n",
    "    questions.append(df[\"question\"][i])\n",
    "    reponses.append(\" | \".join([df[f\"answers.{l}\"][i] for l in df[\"correct_answers\"][i].split(\"|\")]))\n",
    "    total_reponses.append(df[\"correct_answers\"][i])\n",
    "\n",
    "for i,idd in enumerate(ids):\n",
    "    dic[idd] = {\"reponses\":total_reponses[i],\"similarités\":{}}\n",
    "    \n",
    "    resQ = [list(s) for s in cosinus(questions[i],questions)]\n",
    "    resR = [list(s) for s in cosinus(reponses[i],reponses)]\n",
    "    \n",
    "    for j,idd2 in enumerate(ids):\n",
    "        dic[idd][\"similarités\"][idd2] = {\"reponses\":total_reponses[j],\"simQ\":resQ[j][0],\"simR\":resR[j][0]}\n",
    "\n",
    "writeJson(\"sims.json\",dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c47a8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tri des questions par mesure de similarité\n",
    "\n",
    "data = openJson(\"sims.json\")\n",
    "\n",
    "similarities_clusters = []\n",
    "\n",
    "for idQ, subdic in data.items():\n",
    "    sim_clus = []\n",
    "    for k,v in subdic[\"similarités\"].items():\n",
    "        if v[\"simQ\"] > 0.8:\n",
    "            sim_clus.append(k)\n",
    "    similarities_clusters.append(sim_clus)\n",
    "\n",
    "similarities_clusters_clean = []\n",
    "for l in similarities_clusters:\n",
    "    if len(l) > 1:\n",
    "        similarities_clusters_clean.append(l)\n",
    "    \n",
    "#on sauvegarde les clusters en supprimant les clusters similaires ET LES CLUSTERS D'UN ELEMENT\n",
    "writeJson(\"cluster_by_question_similarities.json\",[list(item) for item in set(tuple(row) for row in similarities_clusters_clean)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f1d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/csv/train.csv\",delimiter=\";\")\n",
    "data = openJson(\"cluster_by_question_similarities.json\")\n",
    "\n",
    "questions_list = []\n",
    "for l in data:\n",
    "    new_l = []\n",
    "    for i in range(len(df)):\n",
    "        if df[\"id\"][i] in l:\n",
    "            new_l.append(df[\"question\"][i])\n",
    "    questions_list.append(new_l)\n",
    "    \n",
    "writeJson(\"questions.json\",questions_list) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEFT2023",
   "language": "python",
   "name": "deft2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
